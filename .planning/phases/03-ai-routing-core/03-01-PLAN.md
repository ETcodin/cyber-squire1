---
phase: 03-ai-routing-core
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - COREDIRECTIVE_ENGINE/workflow_supervisor_agent.json
  - COREDIRECTIVE_ENGINE/workflow_tool_system_status.json
autonomous: true

must_haves:
  truths:
    - "LangChain AI Agent node uses Ollama qwen2.5:7b for routing decisions"
    - "System prompt includes tool routing instructions"
    - "AI Agent has access to tool schemas via @n8n/n8n-nodes-langchain.toolWorkflow nodes"
  artifacts:
    - path: "COREDIRECTIVE_ENGINE/workflow_supervisor_agent.json"
      provides: "AI Agent configuration with routing prompt"
      contains: "@n8n/n8n-nodes-langchain.agent"
    - path: "COREDIRECTIVE_ENGINE/workflow_tool_system_status.json"
      provides: "System status tool workflow"
      contains: "toolWorkflowInput"
  key_links:
    - from: "Supervisor Agent node"
      to: "Ollama Qwen model"
      via: "ai_languageModel connection"
      pattern: "lmChatOllama"
    - from: "Supervisor Agent node"
      to: "Tool Workflow nodes"
      via: "ai_tool connection"
      pattern: "toolWorkflow"
---

<objective>
Configure the LangChain AI Agent node in the Supervisor workflow with an enhanced routing prompt that enables intelligent tool selection based on natural language input.

Purpose: Enable AI-driven routing (ROUTE-02) with natural language understanding (ROUTE-03) instead of rigid keyword matching.

Output: AI Agent that can interpret varied natural language inputs and route to appropriate tool workflows.
</objective>

<execution_context>
@/Users/et/.claude/get-shit-done/workflows/execute-plan.md
@/Users/et/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@COREDIRECTIVE_ENGINE/workflow_supervisor_agent.json
@COREDIRECTIVE_ENGINE/workflow_tool_system_status.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Enhance AI Agent system prompt for intelligent routing</name>
  <files>COREDIRECTIVE_ENGINE/workflow_supervisor_agent.json</files>
  <action>
    Update the Supervisor Agent node's system prompt to include explicit routing logic:

    1. Locate the AI Agent node (id: "ai-agent", type: "@n8n/n8n-nodes-langchain.agent")

    2. Enhance the system message to include:
       - Clear tool selection criteria (WHEN to call each tool)
       - Natural language understanding examples (not just keyword matching)
       - Routing confidence guidelines
       - Fallback behavior for ambiguous inputs

    3. Add routing examples to system prompt:
       ```
       ## TOOL ROUTING EXAMPLES

       **System Status Tool:**
       - "Check system health" → System_Status
       - "How is the server doing?" → System_Status
       - "Are all services running?" → System_Status
       - "What's the EC2 status?" → System_Status

       **ADHD Commander Tool:**
       - "What should I work on?" → ADHD_Commander
       - "What's on my plate today?" → ADHD_Commander
       - "I'm stuck, what's the priority task?" → ADHD_Commander
       - "Give me a focus task" → ADHD_Commander

       **Finance Manager Tool:**
       - "Log $50 for groceries" → Finance_Manager
       - "I paid rent today" → Finance_Manager
       - "Track AWS bill" → Finance_Manager
       - "What's my debt status?" → Finance_Manager

       ## ROUTING RULES
       1. Match INTENT not keywords
       2. If 70%+ confident → call tool directly
       3. If <70% confident → ask ONE clarifying question
       4. If completely unclear → respond with available options
       5. Never say "I don't have that capability" - suggest closest tool
       ```

    4. Keep temperature at 0.4 (existing setting) for consistent routing

    5. Ensure existing tool connections remain intact (ADHD_Commander, Finance_Manager)

    Do NOT change:
    - Tool definitions (keep existing descriptions)
    - Model configuration (keep qwen2.5:7b)
    - Memory configuration (keep 13-message window)
    - Other node connections
  </action>
  <verify>
    # Verify AI Agent node exists
    grep -E "@n8n/n8n-nodes-langchain.agent" COREDIRECTIVE_ENGINE/workflow_supervisor_agent.json

    # Check for enhanced routing instructions
    grep -E "TOOL ROUTING|ROUTING RULES" COREDIRECTIVE_ENGINE/workflow_supervisor_agent.json

    # Verify temperature setting
    grep -E '"temperature".*0.4' COREDIRECTIVE_ENGINE/workflow_supervisor_agent.json
  </verify>
  <done>
    AI Agent system prompt includes explicit routing logic with natural language understanding examples and confidence-based decision rules.
  </done>
</task>

<task type="auto">
  <name>Task 2: Verify and document tool workflow connections</name>
  <files>COREDIRECTIVE_ENGINE/workflow_supervisor_agent.json</files>
  <action>
    Audit all tool connections to ensure they're properly wired to the AI Agent:

    1. Verify existing tool nodes:
       - ADHD Commander Tool (id: "tool-adhd")
       - Finance Manager Tool (id: "tool-finance")

    2. Check for System Status tool connection:
       - If missing, document requirement for 03-02-PLAN.md (tool schema definition)
       - If present, verify it has correct workflow ID reference

    3. Verify all tool nodes have:
       - Type: "@n8n/n8n-nodes-langchain.toolWorkflow"
       - Name field (user-facing tool name)
       - Description field (tells AI when to use it)
       - workflowId reference (must match actual workflow ID in n8n)

    4. Validate connection structure in JSON:
       ```json
       "connections": {
         "Tool Name": {
           "ai_tool": [[{
             "node": "Supervisor Agent",
             "type": "ai_tool",
             "index": 0
           }]]
         }
       }
       ```

    5. Document current tool inventory in code comment within JSON:
       ```json
       "meta": {
         "notes": "AI Routing Core v1: Tools connected - ADHD Commander, Finance Manager, System Status (pending). Routing via natural language understanding, not keywords.",
       }
       ```
  </action>
  <verify>
    # Count tool connections
    grep -c "toolWorkflow" COREDIRECTIVE_ENGINE/workflow_supervisor_agent.json
    # Should return at least 2 (ADHD, Finance)

    # Verify ai_tool connections
    grep -E '"ai_tool".*Supervisor Agent' COREDIRECTIVE_ENGINE/workflow_supervisor_agent.json
  </verify>
  <done>
    All tool workflow nodes properly connected to AI Agent. Tool inventory documented in workflow metadata.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add routing decision logging to workflow</name>
  <files>COREDIRECTIVE_ENGINE/workflow_supervisor_agent.json</files>
  <action>
    Insert a logging node after the AI Agent to capture routing decisions:

    1. Add new Code node after "Supervisor Agent" and before "Format Output":
       - ID: "log-routing-decision"
       - Name: "Log Routing Decision"
       - Type: "n8n-nodes-base.code"
       - Position: [1680, 520] (between agent and format)

    2. JavaScript code to extract routing metadata:
       ```javascript
       // Log AI routing decision for monitoring and debugging
       const agent = $input.first().json;
       const timestamp = new Date().toISOString();
       const executionId = $execution.id || 'N/A';

       // Extract tool calls if any
       const toolCalls = agent.intermediate_steps || [];
       const toolNames = toolCalls.map(step => step.tool || 'unknown');

       // Estimate confidence (proxy: response length and tool usage)
       const confidence = toolNames.length > 0 ? 'HIGH' :
                         (agent.output || '').length > 100 ? 'MEDIUM' : 'LOW';

       const logEntry = {
         event: 'routing_decision',
         timestamp,
         executionId,
         tools_called: toolNames,
         confidence_estimate: confidence,
         response_length: (agent.output || '').length,
         has_tool_output: toolNames.length > 0
       };

       console.log('ROUTING_DECISION:', JSON.stringify(logEntry));

       // Pass through original agent output
       return { json: agent };
       ```

    3. Update connections:
       - Change "Supervisor Agent" main output to connect to "Log Routing Decision"
       - Connect "Log Routing Decision" to "Format Output"

    This enables SC-3.4 (routing decision logged with confidence score).
  </action>
  <verify>
    # Check for new logging node
    grep -E "log-routing-decision|Log Routing Decision" COREDIRECTIVE_ENGINE/workflow_supervisor_agent.json

    # Verify connection path
    grep -A5 '"Supervisor Agent"' COREDIRECTIVE_ENGINE/workflow_supervisor_agent.json | grep "Log Routing Decision"
  </verify>
  <done>
    Routing decision logging node inserted into workflow, capturing tool calls and confidence estimates for each message.
  </done>
</task>

<task type="auto">
  <name>Task 4: Test routing with sample inputs (documentation)</name>
  <files>.planning/phases/03-ai-routing-core/03-01-TEST-CASES.md</files>
  <action>
    Create a test case document for validating routing behavior:

    1. Create file: `.planning/phases/03-ai-routing-core/03-01-TEST-CASES.md`

    2. Define 10 test inputs covering success criteria:

       ```markdown
       # Phase 03-01 Routing Test Cases

       ## Success Criteria Coverage

       ### SC-3.1: System health routing (natural language)
       - TC-1: "Check system health" → System_Status
       - TC-2: "Is the server okay?" → System_Status
       - TC-3: "How's EC2 doing?" → System_Status

       ### SC-3.2: ADHD Commander routing
       - TC-4: "What's on my plate today?" → ADHD_Commander
       - TC-5: "Give me a focus task" → ADHD_Commander
       - TC-6: "I don't know what to work on" → ADHD_Commander

       ### SC-3.3: Graceful degradation
       - TC-7: "asdfghjkl" → Clarification or "I didn't understand"
       - TC-8: "banana robot 42" → Clarification response

       ### SC-3.4: General conversation
       - TC-9: "Hello" → Direct response (no tool call)
       - TC-10: "Thanks for the help" → Direct response

       ## Expected Logging Output

       Each test should produce log entry with:
       - `event: 'routing_decision'`
       - `tools_called: []` or `['ADHD_Commander']`
       - `confidence_estimate: 'HIGH'|'MEDIUM'|'LOW'`

       ## Manual Testing Procedure

       1. Deploy updated workflow to n8n
       2. Send each test message via Telegram
       3. Check n8n execution logs for ROUTING_DECISION entries
       4. Verify tool was called (if expected) or direct response given
       5. Record actual vs expected behavior

       ## Pass Criteria

       - 8/10 test cases route correctly
       - All routing decisions logged
       - No system errors or timeouts
       ```

    3. Reference this file in workflow metadata for future testing

    This document will be used in 03-04-PLAN.md for actual testing.
  </action>
  <verify>
    test -f .planning/phases/03-ai-routing-core/03-01-TEST-CASES.md && echo "TEST CASES EXIST"

    grep "SC-3.1" .planning/phases/03-ai-routing-core/03-01-TEST-CASES.md
  </verify>
  <done>
    Test case document created with 10 routing scenarios covering all SC-3.x success criteria.
  </done>
</task>

</tasks>

<verification>
1. AI Agent system prompt includes TOOL ROUTING and ROUTING RULES sections
2. All existing tool connections verified and documented
3. Routing decision logging node inserted after AI Agent
4. Test case document created with 10 routing scenarios
</verification>

<success_criteria>
- SC-3.1 READY: Prompt includes natural language routing examples for system status
- SC-3.2 READY: Prompt includes ADHD Commander routing examples
- SC-3.3 READY: Prompt includes fallback handling for unclear inputs
- SC-3.4 IMPLEMENTED: Routing decision logging captures tool calls and confidence
</success_criteria>

<output>
After completion, create `.planning/phases/03-ai-routing-core/03-01-SUMMARY.md`
</output>
