---
phase: 02-webhook-message-intake
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - COREDIRECTIVE_ENGINE/workflow_supervisor_agent.json
  - COREDIRECTIVE_ENGINE/sql/create_message_log.sql
autonomous: true

must_haves:
  truths:
    - "Duplicate messages (same message_id) are not processed twice"
    - "Messages sent in rapid succession are all processed"
    - "Message order is preserved during burst handling"
  artifacts:
    - path: "COREDIRECTIVE_ENGINE/workflow_supervisor_agent.json"
      provides: "Message deduplication logic"
      contains: "message_id"
    - path: "COREDIRECTIVE_ENGINE/sql/create_message_log.sql"
      provides: "Message log table schema"
      contains: "CREATE TABLE"
  key_links:
    - from: "Telegram Ingestion"
      to: "Parse Input"
      via: "message_id extraction"
      pattern: "message_id"
    - from: "Parse Input"
      to: "PostgreSQL"
      via: "INSERT with ON CONFLICT DO NOTHING"
      pattern: "ON CONFLICT"
---

<objective>
Implement message deduplication and queue handling to prevent duplicate processing and ensure ordered delivery during message bursts.

Purpose: Satisfy ROUTE-07 (queue constraint) and SC-2.2/SC-2.4 (burst handling, no duplicates).

Output: Deduplication logic in supervisor workflow using PostgreSQL message_id tracking.
</objective>

<execution_context>
@/Users/et/.claude/get-shit-done/workflows/execute-plan.md
@/Users/et/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@COREDIRECTIVE_ENGINE/workflow_supervisor_agent.json
@.planning/phases/02-webhook-message-intake/02-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create PostgreSQL message log table schema</name>
  <files>COREDIRECTIVE_ENGINE/sql/create_message_log.sql</files>
  <action>
    Create SQL schema for message deduplication tracking:

    ```sql
    -- Message log table for deduplication
    CREATE TABLE IF NOT EXISTS telegram_message_log (
      message_id BIGINT PRIMARY KEY,          -- Telegram message_id (unique)
      chat_id BIGINT NOT NULL,                -- Chat where message was sent
      user_id BIGINT,                         -- Telegram user who sent it
      message_text TEXT,                      -- Message content (for debugging)
      received_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
      processed_at TIMESTAMP WITH TIME ZONE,
      status VARCHAR(20) DEFAULT 'pending'    -- pending, processing, completed, failed
    );

    -- Index for cleanup queries
    CREATE INDEX IF NOT EXISTS idx_message_log_received
      ON telegram_message_log(received_at);

    -- Index for chat-based queries
    CREATE INDEX IF NOT EXISTS idx_message_log_chat
      ON telegram_message_log(chat_id, received_at DESC);

    -- Auto-cleanup: Remove messages older than 24 hours (prevents table bloat)
    -- Run this as a cron job or scheduled n8n workflow
    -- DELETE FROM telegram_message_log WHERE received_at < NOW() - INTERVAL '24 hours';
    ```

    Store in `COREDIRECTIVE_ENGINE/sql/create_message_log.sql`

    This table:
    - Uses message_id as PRIMARY KEY (natural deduplication via INSERT ... ON CONFLICT DO NOTHING)
    - Tracks processing status for debugging
    - Has cleanup strategy documented
  </action>
  <verify>
    test -f COREDIRECTIVE_ENGINE/sql/create_message_log.sql && echo "SQL file exists"
    grep "CREATE TABLE" COREDIRECTIVE_ENGINE/sql/create_message_log.sql
    grep "PRIMARY KEY" COREDIRECTIVE_ENGINE/sql/create_message_log.sql
  </verify>
  <done>
    SQL schema file exists with message_id as primary key for deduplication.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add deduplication logic to Supervisor Agent workflow</name>
  <files>COREDIRECTIVE_ENGINE/workflow_supervisor_agent.json</files>
  <action>
    Modify workflow_supervisor_agent.json to add message deduplication:

    1. After "Telegram Ingestion" node, add a new "Check Duplicate" node:
       - Type: `n8n-nodes-base.postgres`
       - Operation: Execute Query
       - Query:
         ```sql
         INSERT INTO telegram_message_log (message_id, chat_id, user_id, message_text, status)
         VALUES ($1, $2, $3, $4, 'processing')
         ON CONFLICT (message_id) DO NOTHING
         RETURNING message_id;
         ```
       - Parameters: `[{{ $json.message.message_id }}, {{ $json.message.chat.id }}, {{ $json.message.from.id }}, {{ $json.message.text }}]`
       - Credential: `cd-postgres-main`

    2. Add a conditional "Is Duplicate?" node after Check Duplicate:
       - Type: `n8n-nodes-base.if`
       - Condition: `{{ $json.length === 0 }}` (empty result = duplicate, row exists)
       - True (duplicate): Connect to new "Skip Duplicate" node (No-Op/Log)
       - False (new): Continue to existing "Parse Input" node

    3. Update connections:
       - Telegram Ingestion -> Check Duplicate
       - Check Duplicate -> Is Duplicate?
       - Is Duplicate? (false/new) -> Parse Input
       - Is Duplicate? (true/duplicate) -> Skip Duplicate (new terminal node)

    4. Add "Skip Duplicate" node:
       - Type: `n8n-nodes-base.noOp` or Code node that logs "Duplicate message skipped"

    5. At end of workflow (after "Send Response"), add "Mark Complete" node:
       - Type: `n8n-nodes-base.postgres`
       - Query:
         ```sql
         UPDATE telegram_message_log
         SET status = 'completed', processed_at = NOW()
         WHERE message_id = $1;
         ```
       - Parameter: `[{{ $('Telegram Ingestion').item.json.message.message_id }}]`
  </action>
  <verify>
    grep "telegram_message_log" COREDIRECTIVE_ENGINE/workflow_supervisor_agent.json
    grep "ON CONFLICT" COREDIRECTIVE_ENGINE/workflow_supervisor_agent.json
    grep -c "postgres" COREDIRECTIVE_ENGINE/workflow_supervisor_agent.json
    # Should show multiple PostgreSQL operations
  </verify>
  <done>
    Supervisor workflow checks message_id before processing, skips duplicates, and marks messages as completed.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create database table on EC2 PostgreSQL</name>
  <files></files>
  <action>
    Execute the SQL schema on the EC2 PostgreSQL instance:

    1. Transfer SQL file to EC2:
       ```bash
       scp -i ~/.ssh/cyber-squire-key.pem COREDIRECTIVE_ENGINE/sql/create_message_log.sql \
           ec2-user@54.234.155.244:/tmp/
       ```

    2. Execute SQL via docker exec:
       ```bash
       ssh -i ~/.ssh/cyber-squire-key.pem ec2-user@54.234.155.244 \
         'docker exec -i cd-service-db psql -U postgres -d coredirective < /tmp/create_message_log.sql'
       ```

    3. Verify table exists:
       ```bash
       ssh -i ~/.ssh/cyber-squire-key.pem ec2-user@54.234.155.244 \
         'docker exec cd-service-db psql -U postgres -d coredirective -c "\d telegram_message_log"'
       ```

    If SSH key not available, document manual execution steps for user.
  </action>
  <verify>
    # If SSH available, verify table
    ssh -i ~/.ssh/cyber-squire-key.pem ec2-user@54.234.155.244 \
      'docker exec cd-service-db psql -U postgres -d coredirective -c "SELECT COUNT(*) FROM telegram_message_log;"' 2>/dev/null || \
      echo "SSH not available - manual verification required"
  </verify>
  <done>
    PostgreSQL table `telegram_message_log` created on EC2, or deployment instructions documented.
  </done>
</task>

</tasks>

<verification>
1. SQL schema file exists at `COREDIRECTIVE_ENGINE/sql/create_message_log.sql`
2. Supervisor workflow includes deduplication nodes
3. Workflow JSON valid (parseable with jq)
4. PostgreSQL table created or instructions provided
</verification>

<success_criteria>
- SC-2.2 READY: Burst handling via PostgreSQL queue (INSERT with ON CONFLICT)
- SC-2.4 READY: Duplicate prevention via message_id primary key
</success_criteria>

<output>
After completion, create `.planning/phases/02-webhook-message-intake/02-02-SUMMARY.md`
</output>
