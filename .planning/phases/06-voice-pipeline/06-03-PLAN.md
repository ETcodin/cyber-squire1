---
phase: 06-voice-pipeline
plan: 03
type: execute
wave: 3
depends_on: [06-02]
files_modified:
  - COREDIRECTIVE_ENGINE/workflows/voice_handler.json

must_haves:
  truths:
    - "Voice file converted to format accepted by faster-whisper"
    - "Transcription request sent to faster-whisper API"
    - "Transcription text extracted from response"
  artifacts:
    - path: "COREDIRECTIVE_ENGINE/workflows/voice_handler.json"
      provides: "Transcription API integration"
      contains: "faster-whisper HTTP request"
---

<objective>
Integrate faster-whisper transcription API into voice pipeline.

Purpose: Send downloaded voice file to faster-whisper and receive transcription text. This completes the voice-to-text conversion needed for AI routing.

Output: Voice notes transcribed to text and ready for AI processing.
</objective>

<execution_context>
@/Users/et/.claude/get-shit-done/workflows/execute-plan.md
@/Users/et/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/06-voice-pipeline/06-01-SUMMARY.md
@.planning/phases/06-voice-pipeline/06-02-SUMMARY.md
faster-whisper-server API: https://github.com/fedirz/faster-whisper-server
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add format conversion check</name>
  <files>COREDIRECTIVE_ENGINE/workflows/voice_handler.json</files>
  <action>
    After downloading voice file, check MIME type:

    1. IF node: Check `message.voice.mime_type`
    2. If "audio/ogg" or "audio/oga": Proceed directly
    3. If other format: Log warning (Telegram should always send .oga)

    Note: Telegram voice notes are always Ogg/Opus format (.oga extension)
    faster-whisper accepts Ogg format directly, no conversion needed

    If conversion IS needed (edge case):
    - Use ffmpeg via SSH: `ffmpeg -i input.oga -ar 16000 output.wav`
    - But this should not be necessary for normal Telegram voice notes
  </action>
  <verify>
    # Check workflow has MIME type validation
    # Most cases will pass through without conversion
  </verify>
  <done>MIME type check added to handle edge cases</done>
</task>

<task type="auto">
  <name>Task 2: Send to faster-whisper API</name>
  <files>COREDIRECTIVE_ENGINE/workflows/voice_handler.json</files>
  <action>
    Add HTTP Request node to call faster-whisper:

    Configuration:
    - URL: `http://cd-service-whisper:8000/v1/audio/transcriptions`
    - Method: POST
    - Authentication: None (internal Docker network)
    - Body: multipart/form-data
      - file: Binary data from previous step
      - model: "base"
      - language: "en"
      - response_format: "json"

    Response format:
    ```json
    {
      "text": "transcribed text here"
    }
    ```

    Note: Using Docker network hostname (cd-service-whisper) not localhost
  </action>
  <verify>
    # Send test voice note
    # Check execution log shows transcription API call
    # Response should contain "text" field with transcription
  </verify>
  <done>faster-whisper API integration complete</done>
</task>

<task type="auto">
  <name>Task 3: Extract and echo transcription</name>
  <files>COREDIRECTIVE_ENGINE/workflows/voice_handler.json</files>
  <action>
    After receiving transcription response:

    1. Set variable: Extract `text` field from JSON response
    2. Telegram Send Message:
       - Message: `You said: "{{$node["Whisper"].json["text"]}}"`
       - parse_mode: Markdown (for quote formatting)

    This satisfies VOICE-04 requirement (echo transcription before executing).

    User sees:
    1. "Transcribing..." (from 06-02)
    2. "You said: [transcription]" (from this step)
    3. Then AI response (from routing pipeline)
  </action>
  <verify>
    # Send voice note
    # Verify echo message shows transcription text
  </verify>
  <done>Transcription echoed to user with confirmation</done>
</task>

<task type="auto">
  <name>Task 4: Route transcription to AI pipeline</name>
  <files>COREDIRECTIVE_ENGINE/workflows/voice_handler.json</files>
  <action>
    After echoing transcription:

    1. Set variable: Create message object:
       ```json
       {
         "message": {
           "text": "{{$node["Whisper"].json["text"]}}",
           "from": "{{$json.message.from}}",
           "chat": "{{$json.message.chat}}",
           "message_id": "{{$json.message.message_id}}",
           "is_voice_transcription": true
         }
       }
       ```
    2. Execute Workflow: Call AI routing workflow (from Phase 3)
       - Pass transcribed text as if it were typed message
       - Flag `is_voice_transcription` for logging

    This completes the loop: voice → text → AI routing → response
  </action>
  <verify>
    # Send voice note with command (e.g., "check system status")
    # Verify AI routes correctly and executes command
    # Transcription should behave identically to typed text
  </verify>
  <done>Transcription routed through existing AI pipeline</done>
</task>

</tasks>

<verification>
1. Send voice note to bot
2. Verify "Transcribing..." appears within 2 seconds
3. Verify "You said: [text]" appears after transcription
4. Verify AI response appears (command executed)
5. Check execution log shows all steps completed
</verification>

<success_criteria>
- Voice note transcribed by faster-whisper
- Transcription echoed to user
- Transcription routed to AI pipeline
- End-to-end: voice input → AI response
</success_criteria>

<output>
After completion, create `.planning/phases/06-voice-pipeline/06-03-SUMMARY.md`
</output>
