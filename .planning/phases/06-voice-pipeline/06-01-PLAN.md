---
phase: 06-voice-pipeline
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - COREDIRECTIVE_ENGINE/docker-compose.yaml

must_haves:
  truths:
    - "faster-whisper container responds to health check"
    - "Docker compose stack includes faster-whisper service"
  artifacts:
    - path: "COREDIRECTIVE_ENGINE/docker-compose.yaml"
      provides: "faster-whisper service definition"
      contains: "faster-whisper container configuration"
  key_links:
    - from: "docker-compose.yaml"
      to: "cd-service-whisper container"
      via: "service definition"
      pattern: "cd-service-whisper"
---

<objective>
Add faster-whisper Docker container to compose stack for voice transcription.

Purpose: Enable voice note processing by adding local transcription capability. This prevents external API dependencies and keeps voice data private while providing fast transcription for ADHD workflows.

Output: Updated docker-compose.yaml with faster-whisper service and verified container health.
</objective>

<execution_context>
@/Users/et/.claude/get-shit-done/workflows/execute-plan.md
@/Users/et/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@COREDIRECTIVE_ENGINE/docker-compose.yaml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add faster-whisper service to docker-compose.yaml</name>
  <files>COREDIRECTIVE_ENGINE/docker-compose.yaml</files>
  <action>
    Add faster-whisper service to docker-compose.yaml:

    ```yaml
    cd-service-whisper:
      image: fedirz/faster-whisper-server:latest-cpu
      container_name: cd-service-whisper
      restart: always
      ports:
        - "8000:8000"
      volumes:
        - ./CD_VOL_WHISPER:/root/.cache/huggingface:z
      environment:
        - WHISPER_MODEL=base
        - WHISPER_LANGUAGE=en
      healthcheck:
        test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
        interval: 30s
        timeout: 10s
        retries: 3
        start_period: 60s
    ```

    Configuration notes:
    - Using CPU version to avoid GPU memory conflicts with Ollama
    - base model provides good balance of speed vs accuracy
    - Volume for model caching to avoid re-downloads
    - Health check ensures service readiness
  </action>
  <verify>
    grep "cd-service-whisper" COREDIRECTIVE_ENGINE/docker-compose.yaml
    # Should return the service definition
  </verify>
  <done>docker-compose.yaml contains cd-service-whisper service definition</done>
</task>

<task type="auto">
  <name>Task 2: Deploy faster-whisper container</name>
  <files>None (remote execution)</files>
  <action>
    SSH to EC2 and deploy the faster-whisper service:

    1. SSH to EC2: `ssh -i ~/cyber-squire-ops/cyber-squire-ops.pem ec2-user@54.234.155.244`
    2. Navigate to stack: `cd /opt/COREDIRECTIVE_ENGINE`
    3. Pull or copy updated docker-compose.yaml
    4. Start whisper service: `docker compose up -d cd-service-whisper`
    5. Wait for model download (first run may take 2-3 minutes)
    6. Verify health: `docker compose ps cd-service-whisper`
    7. Test endpoint: `curl http://localhost:8000/health`

    Expected output: `{"status":"ok"}` or similar health indicator

    Note: First startup will download the base model (~140MB)
  </action>
  <verify>
    ssh -i ~/cyber-squire-ops/cyber-squire-ops.pem ec2-user@54.234.155.244 \
      "docker compose -f /opt/COREDIRECTIVE_ENGINE/docker-compose.yaml ps cd-service-whisper"
    # Should show container running and healthy
  </verify>
  <done>faster-whisper container running and healthy on EC2</done>
</task>

<task type="auto">
  <name>Task 3: Test transcription endpoint</name>
  <files>None (remote execution)</files>
  <action>
    Test the faster-whisper API with a sample audio file:

    1. Download test audio: `curl -o /tmp/test.wav https://github.com/ggerganov/whisper.cpp/raw/master/samples/jfk.wav`
    2. Send to whisper: `curl -X POST -F "file=@/tmp/test.wav" http://localhost:8000/v1/audio/transcriptions`
    3. Verify response contains transcription text

    Expected: JSON response with transcription of JFK audio

    Note: This validates the API is functional before integrating with n8n
  </action>
  <verify>
    # Test will be done during deployment
    # Success: Transcription returned in JSON format
  </verify>
  <done>faster-whisper API returns transcription for test audio</done>
</task>

</tasks>

<verification>
1. Configuration check: `grep "cd-service-whisper" COREDIRECTIVE_ENGINE/docker-compose.yaml` returns service definition
2. Runtime check: `docker compose ps cd-service-whisper` shows healthy status
3. Functional check: `curl http://localhost:8000/health` returns success
4. API test: Test audio transcription returns expected text
</verification>

<success_criteria>
- cd-service-whisper in docker-compose.yaml
- Container running and healthy in Docker
- Health endpoint returns 200 OK
- Test transcription completes successfully
</success_criteria>

<output>
After completion, create `.planning/phases/06-voice-pipeline/06-01-SUMMARY.md`
</output>
